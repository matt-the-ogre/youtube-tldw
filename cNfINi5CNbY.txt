
>> Since day one, we set out tosignificantly improve the livesof as many people as possible.And with a little help, youfound new answers, discoverednew places.The right words came at just theright time.And we even learned how to spellthe word epicurean.Life got a little easier.Our photos got a little better.And we got closer to a worldwhere we all belong.
>> All stations ready to resumecount, 3 2 1... we have liftoff!
>> So as we stand on the cusp ofa new area, new breakthroughs inAI will reimagine the ways wecan help.We will have the chance toimprove the lives of billions ofpeople.We will give businesses theopportunity to thrive and grow,and help society answer thetoughest questions we have toface.Now, we don't take this forgranted.So while our ambition is bold,our approach will always beresponsible, because our goal isto make AI helpful for everyone.
[Cheers and Applause].

>>SUNDAR: Good morning,everyone.Welcome to Google I/O.
[Cheers and Applause].
It's great to see so manyof you here at Shoreline, so many developers,and a huge thanks to themillions joining from around theworld, from Bangladesh to Brazilto our new Bay View Campus rightnext door.It's so great to have you, asalways.As you may have heard, AI ishaving a very busy year, sowe've got lots to talk about.Let's get started.Seven years into our journey, asan AI first company, we are atan exciting inflection point.We have an opportunity to makeAI even more helpful for people,for businesses, for communities,for everyone.We have been applying AI to makeour products radically morehelpful for a while.With generative AI, we're takingthe next step.With a bold and responsibleapproach, we're re imagining allour core products, includingSearch.You will hear more later in the keynote.Let me start with a few examplesof how generative AI is helpingto evolve our products, startingwith G mail.In 2017, we launched SmartReply, short responses you couldselect with just one click.Next came Smart Compose, whichoffered writing suggestions asyou type.Smart Compose led to moreadvanced writing featurespowered by AI.They've been used in WorkSpaceover 180 billion times in thepast year alone.And now, with a much morepowerful generative model, weare taking the next step inG mail with "Help me write."Let's say you got this E mailthat your flight was cancelled.The airline has sent you avoucher, but what you reallywant is a full refund.You could reply and use Help MeWrite.Just type in the prompt of whatyou want, and E mail to ask fora full refund, hit create, and afull draft appears.As you can see, it convenientlypulled in flight details fromthe previous E mail.And it looks pretty close towhat you want to send.Maybe you want to refine itfurther.In this case, a more elaborateE mail might increase thechances of getting the refund.
[Laughter].

[Applause].
And there you go.I think it's ready to send!Help me write will start rollingout as part of our WorkSpaceupdates.And just like with SmartCompose, you will see it getbetter over time.The next example is Maps.Since the early days of StreetView, AI has stitched togetherbillions of panoramic images sopeople can explore the worldfrom their device.At last year's I/O, weintroduced Immersive View, whichuses AI to create a highfidelity representation of aplace so you can experience itbefore you visit.Now we are expanding that sametechnology to do what Maps doesbest: Help you get where youwant to go.Google Maps provides 20 billionkilometers of directions everyday.That's a lot of trips.Imagine if you could see yourwhole trip in advance.With Immersive View for routes,now you can, whether you'rewalking, cycling or driving.Let me show you what I mean.Say I'm in New York City and Iwant to go on a bike ride.Maps has given me a couple ofoptions close to where I am.I like the one on thewaterfront, so let's go withthat.Looks scenic.And I want to get a feel for itfirst.Click on immersive view forroutes.And it's an entirely new way to look at myjourney.I can zoom in to get anincredible bird's eye view ofthe ride.And as we turn, we get on to agreat bike path.
[Cheers and Applause].
It looks like it's going to be a beautifulride.You can also check today's airquality.Looks really AQI is 43.Pretty good.And if I want to check trafficand weather and see how theymight change over the next fewhours, I can do that.Looks like it's going to pourlater, so maybe I want to getgoing now.Immersive View for routes willbegin to roll out over thesummer and launch in 15 citiesby the end of the year,including London, New York,Tokyo and San Francisco.
[Cheers and Applause].
Another product made better byAI is Google Photos.We introduced it at I/O in 2015,and it was one of our first AInative products.Breakthroughs in machinelearning made it possible tosearch your photos for thingslike people, sunsets orwaterfalls.Of course, we want you to domore than just search photos.We also want to help you makethem better.In fact, every month, 1.7billion images are edited inGoogle photos.AI advancements give us morepowerful ways to do this.For example, Magic Eraser,launched first on Pixel, usesAI powered computationalphotography to remove unwanted distractions.And later this year, using acombination of semanticunderstanding and generative AI,you can do much more with thenew experience called MagicEditor.Let's have a look.Say you're on a hike and stop totake a photo in front of awaterfall.You wish you had taken your bagoff for the photo, so let's goahead and remove that bag strap.The photo feels a bit dark, soyou can improve the lighting.And maybe you want to even getrid of some clouds to make itfeel as sunny as you rememberit.
[Laughter].
Looking even closer, you wishyou had posed so it looks likeyou're really catching the waterin your hand.No problem.You can adjust that.
[Laughter].

[Applause].
There you go.Let's look at one more photo.This is a great photo, but as aparent, you always want your kid at the centerof it all.And it looks like the balloonsgot cut off in this one.So you can go ahead andreposition the birthday boy.Magic Editor automaticallyre creates parts of the benchand balloons that were notcaptured in the original shot.And as a finishing touch, youcan punch up the sky.This also changes the lightingin the rest of the photo so theedit feels consistent.It's truly magical.We are excited to roll out MagicEditor in Google Photos laterthis year.
[Cheers and Applause].
From G mail and Photos to Maps,these are just a few examples ofhow AI can help you in momentsthat matter.And there is so much more we cando to deliver the full potentialof AI across the products youknow and love.Today, we have 15 products thateach serve more than half abillion people and businesses,and six of those products serveover two billion users each.This gives us so manyopportunities to deliver on ourmission, to organize the world'sinformation and make ituniversally accessible anduseful.It's a timeless mission thatfeels more relevant with eachpassing year.And looking ahead, making AIhelpful for everyone, is themost profound way we willadvance our mission.And we are doing this in four important ways.First, by improving yourknowledge and learning, anddeepening your understanding ofthe world.Second, by boosting creativityand productivity so you canexpress yourself and get thingsdone.Third, by enabling developersand businesses to build theirown transformative products andservices.And finally, by building anddeploying AI responsibly so thateveryone can benefit equally.We are so excited by theopportunities ahead.Our ability to make AI helpfulfor everyone relies oncontinuously advancing ourfoundation models.So I want to take a moment toshare how we are approachingthem.Last year, you heard us talkabout PaLM, which led to manyimprovements across ourproducts.Today, we are ready to announceour latest PaLM model inproduction, PaLM 2.
[Cheers and Applause].
PaLM 2 builds on our fundamentalresearch and our latestinfrastructure.It's highly capable at a widerange of tasks, and easy todeploy.We are announcing over 25products and features powered byPaLM 2 today.PaLM 2 models deliver excellentfoundational capabilities acrossa wide range of sizes.We have affectionately namedthem Gecko, Otter, Bison andUnicorn.Gecko is so light weight that itcan work on mobile devices, fastenough for great interactiveapplications on device, evenwhen offline.PaLM 2 models are stronger inlogic and reasoning, thanks tobroad training on scientific andmathematical topics.It's also trained onmulti lingual texts, spanningover 100 languages so itunderstands and generatesnuanced results.Combined with powerful codingcapabilities, PaLM 2 can alsohelp developers collaboratingaround the world.Let's look at this example.Let's say you're working with acolleague in Seoul and you'redebugging code.You can ask it to fix a bug andhelp out your teammate by addingcomments in Korean to the code.It first recognizes the code isrecursive, suggests a fix and even explainsthe reasoning behind the fix.And as you can see, it added comments in Korean,just like you asked.
[Applause].
While PaLM 2 is highly capable,it really shines when fine tunedon domain specific knowledge.We recently released Sec PaLM, aversion of PaLM 2, fine tunedfor security use cases.It uses AI to better detectmalicious scripts and can helpsecurity experts understand andresolve threats.Another example is Med PaLM 2.In this case, it's fine tuned onmedical knowledge.This fine tuning achieved a 9xreduction in inaccuratereasoning when compared to themodel, approaching theperformance of clinician expertswho answered the same set ofquestions.In fact, Med PaLM 2 was thefirst language model to performat "expert level" on medicallicensing exam style questions,and is currently thestate of the art.We are also working to addcapabilities to Med PaLM 2 sothat it can synthesizeinformation from medical imaginglike plain films and mammograms.You can imagine an AIcollaborator that helpsradiologists, interpret imagesand communicate the results.These are some examples of PaLM2 being used in specializeddomains.We can't wait to see it used inmore.That's why I'm pleasedannounce that it is nowavailable in preview.And I'll let Thomas share more.
[Applause].
PaLM 2 is the latest step in ourdecade long journey to bring AIin responsible ways to billionsof people.It builds on progress made bytwo world class teams, the BrainTeam and DeepMind.Looking back at the defining AIbreakthroughs over the lastdecade, these teams havecontributed to a significantnumber of them.AlphaGo, Transformers,sequence to sequence models, andso on.All this helped set the stagefor the inflection point we areat today.We recently brought these twoteams together in to a singleunit, Google DeepMind.Using the computationalresources of Google, they arefocused on building more capablesystems safely and responsibly.This includes our nextgeneration foundation model,Gemini, which is still intraining.Gemini was created from theground up to be multi modal,highly efficient at tool and APIintegrations, and built toenable future innovations likememory and planning.While still early, we're alreadyseeing impressive multi modalcapabilities not seen in priormodels.Once fine tuned and rigorouslytested for safety, Gemini willbe available at various sizesand capabilities just like PaLM2.As we invest in more advancedmodels, we are also deeplyinvesting in AI responsibility.This includes having the toolsto identify syntheticallygenerated content whenever youencounter it.Two important approaches arewatermarking and metadata.Watermarking embeds informationdirectly into content in waysthat are maintained even throughmodest image editing.Moving forward, we are buildingour models to includewatermarking and other techniques from thestart.So if you look at this syntheticimage, it's impressive how realit looks, so you can imagine howimportant this is going to be inthe future.Metadata allows content creatorsto associate additional contextwith original files, giving youmore information whenever youencounter an image.We'll ensure every one of ourAI generated images has thatmetadata.James will talk about ourresponsible approach to AIlater.As models get better and morecapable, one of the mostexciting opportunities is makingthem available for people toengage with directly.That's the opportunity we havewith Bard, our experiment forconversational AI.We are rapidly evolving Bard.It now supports a wide range ofprogramming capabilities, andit's gotten much smarter atreasoning and math prompts.And as of today, it is now fullyrunning on PaLM 2.To share more about what'scoming, let me turn it over toSissie.
[Cheers and Applause].

>>SISSIE HSIAO: Thanks, Sundar.Large language models havecaptured the world'simagination, changing how wethink about the future ofcomputing.We launched Bard as a limitedaccess experiment on alightweight large language modelto get feedback and iterate.Since then, the team has beenworking hard to make rapidimprovements,and launch themquickly.With PaLM 2 Bard's math, logicand reasoning skills made a hugeleap forward, underpinning itsability to help developers withprogramming.Bard can now collaborate ontasks like code generation,debugging and explaining codesnippets.Bard has already learned morethan 20 programming languages,including C++, Go, JavaScript,Python, Kotlin, and even GoogleSheets functions.And we're thrilled to see thatcoding has quickly become one ofthe most popular things peopleare doing with Bard.So let's take a look at an example.I've recently been learningchess, and, for fun, I thoughtI'd see if I can program a movein Python.How would I use Python togenerate the "Scholar's Mate"move in chess?Okay.Here, Bard created a script tore create this chess move inPython.And notice how it also formatted the codenicely, making it easy to read.We've also heard great feedbackfrom developers about how Bardprovides code citations.And starting next week, you'llnotice something right here.We're making code citations evenmore precise.If Bard brings in a block ofcode, just click this annotationand Bard will underline theblock and link to the source.Now, Bard can also help me understand thecode.Could you tell me what'chess.Board(
[)]'
 does in thiscode?Now, this is a super helpfulexplanation of what it's doingand makes things more clear.All right.Let's see if we can make thiscode a little better.How would I improve this code?Okay.Let's see, there's a list comprehension, creatinga function, and using a generator.Those are great suggestions!Now, could you join them in toone single Python code block?Okay.Bard is rebuilding the code withthese improvements.Okay.Great.How easy was that?And in a couple clicks, I canmove this directly into Colab.Developers love the ability tobring code from Bard into theirworkflow, like Colab, socoming soon, we're adding theability to export and run codewith our partner Replit,starting with Python.
[Cheers and Applause].
We've also heard that you wantDark theme, so starting today,you can activate it
[Cheers and Applause].
You can activate it right in Bard or let itfollow your OS settings.Speaking of exporting things,people often ask Bard for a headstart drafting E mails anddocuments.So today we're launching twomore Export Actions, making iteasy to move Bard's responsesright in to G mail and Docs.
[Cheers and Applause].
So we're excited by how quicklyBard and the underlying modelsare improving, but we're notstopping there.We want to bring morecapabilities to Bard to fuelyour curiosity and imagination.And so, I'm excited to announce that toolsare coming to Bard.
[Cheers and Applause].
As you collaborate with Bard,you'll be able to tap intoservices from Google andextensions with partners to letyou do things never beforepossible.And of course, we'll approachthis responsibly, in a secureand private way, letting youalways stay in control.We're starting with some of theGoogle apps that people love anduse every day.It's incredible what Bard canalready do with text, but imagesare such a fundamental part ofhow we learn and express.So in the next few weeks, Bardwill become more visual, both inits responses, and your prompts.So if you ask, What are somemust see sights in New Orleans?Bard's going to use Google Search and theKnowledge Graph to find the most relevantimages.Okay.Here we go.Hmmm, the French Quarter, theGarden District.These images really give me amuch better sense of what I’mexploring.We'll also make it easy for youto prompt Bard with images,giving you even more ways toexplore and create.People love Google Lens, and incoming months, we're bringingthe powers of Lens to Bard.
[Cheers and Applause].
So if you're looking to havesome fun with your fur babies,you might upload an image andask Bard to "Write a funnycaption about these two."Lens detects this is a photo ofa goofy German Shepherd and aGolden Retriever.And then Bard uses that to create some funnycaptions.If you ask me, I think they're both good boys.Okay.Let's do another one.Imagine I'm 18 and I need to apply to college.I won't date myself with howlong it's been, but it's stillan overwhelming process.So I'm thinking about colleges, but I'm notsure what I want to focus on.I'm into video games.And what kinds of programs might be interesting?Okay.This is a really helpful headstart.Hmmm, animation looks prettyinteresting.Now I could ask, help me find colleges withanimation programs in Pennsylvania.Okay.Great.That's a good list of schools.Now, to see where these are, Imight now say, show these on a map.Here, Bard's using Google Mapsto visualize where these schoolsare.
[Cheers and Applause].
This is super helpful, andexciting to see that plenty ofoptions are not too far fromhome.Now, let's start organizingthings a bit.Show these options as a table.Nice.Structured and organized.But there's more I want to know.Add a column showing whetherthey are public or privateschools.
[Applause].
Perfect.This is a great start to buildon.And now, let's move this to Google Sheetsso my family can jump in later to help mewith my search.
[Cheers and Applause].
You can see how easy it will beto get a jump start in Bard andquickly have something useful tomove over to apps like Docs orSheets to build on with others.Okay.Now, that's a taste of what'spossible when Bard meets some ofGoogle's apps, but that's justthe start.Bard will be able to tapinto all kinds of services fromacross the Web, with extensionsfrom incredible partners likeInstacart, Indeed, Khan Academyand many more.Here's a look at one coming inthe next couple months.With Adobe Firefly, you'll beable to generate completely newimages from your imagination,right in Bard.Now, let's say I'm planning abirthday party for myseven year old who lovesunicorns.I want a fun image to send outwith the invitations.Make an image of a unicorn and acake at a kid's party.Okay.Now Bard is working with Fireflyto bring what I imagined tolife.
[Cheers and Applause].
How amazing is that?This will unlock all kinds ofways that you can take yourcreativity further and faster.And we are so excited for thispartnership.Bard continues to rapidlyimprove and learn new abilities,and we want to let people aroundthe world try it out and sharetheir feedback.And so today, we are removingthe wait list and opening upBard to over 180 countries andterritories.
[Cheers and Applause].
With more coming soon.Bard is also becoming available in more languages.Beyond English, starting today, you'll beable to talk to Bard in Japanese and Korean.
[Cheers and Applause].
Adding languages responsibly involves deepwork to get things like quality and localnuances right, and we're pleased to sharethat we're on track to support 40 languagessoon!It's amazing to see the rate ofprogress so far.More advanced models, so manynew capabilities, and theability for even more people tocollaborate with Bard.And when we're ready to moveBard to our Gemini model, I'mreally excited about moreadvancements to come.So that's where we're going withBard, connecting tools fromGoogle and amazing servicesacross the Web, to help you doand create anything you canimagine.Through a fluid collaborationwith our most capable largelanguage models.There's so much to share in the days ahead.And now, to hear more about how large languagemodels are enabling next generation productivityfeatures right in WorkSpace, I'll hand itover to Aparna.
[Cheers and Applause].

>>APARNA PAPPU: From the verybeginning, Workspace was builtto allow you to collaborate inrealtime with other people.Now you can collaborate in real time withAI.AI can act as a coach, a thoughtpartner, source of inspiration,as well as a productivitybooster across all of the appsof Workspace.Our first steps with AI as acollaborator were via the help me write featurein G mail and Docs, which launched to trustedtesters in March.We've been truly blown away bythe clever and creative waysthese features are being used,from writing essays, salespitches, project plans, clientoutreach, and so much more.Since then, we've been busyexpanding these helpful featuresacross more surfaces.Let me show you a few examples.One of our most popular usecases is the trusty jobdescription.Every business, big or small,needs to hire people.A good job description can make all the difference.Here's how Docs has beenhelping.Say you run a fashion boutiqueand need to hire a textiledesigner.To get started, you enter just afew words as a prompt, "Seniorlevel job description fortextile designer."Docs will take that prompt andsend it to our PaLM 2 basedmodel.And let's see what I get back.Nod bad.With just seven words, the modelcame back with a good startingpoint, written out reallynicely.Now, you can take that and customize it forthe kind of experience, education and skillset that this role needs, saving you a tonof time and effort.
[Applause].
Next, let me show you how youcan get more organized withSheets.Imagine you run a dog walkingbusiness and need to keep trackof things like your clients,logistics about the dogs, likewhat time they need to bewalked, for how long, et cetera.Sheets can help you getorganized.In a new Sheet, simply typesomething like,"Client and petroster for a dog walkingbusiness with rates," and hitCreate.Sheets sends this input to afine tuned model that we've beentraining with all sorts ofSheets specific use cases.Look at that!
[Cheers and Applause].
The model figured out what you might need.The again rated table has things like thedog's name, client info, notes, et cetera.This is a good start for you to tinker with.Sheets made it easy for you toget started, so you can get backto doing what you love.Speaking of getting back tothings you love, let's talkabout Google Slides.People use Slides forstorytelling all the time,whether at work or in theirpersonal lives.For example, you get yourextended family to collectanecdotes/haikus/jokes for yourparents' 50th weddinganniversary in a slide deck.Everyone does their bit, butmaybe this deck could have morepizzazz.Let's pick one of the slides anduse the poem on there as aprompt for image generation."Mom loves her pizza cheesy andtrue, while Dad's favorite treatis a warm pot of fondue."Let's hit create and see what it comes upwith.Behind the scenes, that quote issent as input to ourtext 2 image models.And we know it's unlikely thatthe user will be happy with justone option so we generate six toeight images so that you havethe ability to choose andrefine.Whoa!I have some oddlydelicious looking fondue pizzaimages!Now, the style is a little toocartoony for me.So I'm going to ask it to try again.Let's change the style to"photography."And give it a whirl.Just as weird, but it works forme.
[Cheers and Applause].
You can have endless fun withthis, with no limits oncheesiness or creativity.Starting next month, trustedtesters will be able to try thisand six more generative AIfeatures across Workspace.And later this year, all of thiswill be generally available tobusiness and consumer Workspaceusers via a new service calledDuet AI for Workspace.
[Cheers and Applause].
Stepping back a bit, I showedyou a few powerful examples ofhow Workspace can help you getmore done with just a few wordsas prompts.Prompts are a powerful way ofcollaborating with AI.The right prompt can unlock farmore from these models.However, it can be daunting formany of us to even know where tostart.Well, what if we could solvethat for you?What if AI could proactivelyoffer you prompts?Even better, what if theseprompts were actually contextualand changed based on what youare working on?I am super excited to show you apreview of just that.This is how we see the future ofcollaboration with AI coming tolife.Let's switch to a live demo so Ican show you what I mean.Tony's here to help with that.Hey, Tony.
>> TONY: Hey, Aparna.
[Cheers and Applause].

>>APARNA PAPPU: My niece, Meera, and Iare working on a spooky storytogether for summer camp.We've already written a fewparagraphs, but now we're stuck.Let's get some help.As you can see, we launched aside panel, something the teamfondly calls Sidekick.Sidekick instantly reads andprocesses the document, andoffers some really neatsuggestions, along with anopen prompt dialogue.If we look closely, we can seesome of the suggestions, like, what happenedto the golden seashell?What are common mystery plot twists?Let's try the seashell option and see whatit comes back with.What's happening behind thescenes is that we've providedthe document as context to themodel, along with the suggestedprompt.Let's see what we got.The golden seashell was eaten by a giant squidthat lives in the cove?This is a good start.Let's insert these ideas asnotes so we can continue ourlittle project.Now, one of the interestingobservations we have is thatit's actually easier to react tosomething or perhaps use thatto say, hmmm, I want to goin a different direction.And this is exactly what AI can help with.I see a new suggestion forgenerating images.Let’s see what this does.This story has a village, agolden seashell and some otherdetails.Instead of having to type allthat out, the model picks upthese details from the documentand generates images.These are some cool pictures, and I bet myniece will love these.let's insert them into the docfor fun.Thank you, Tony!
[Cheers and Applause].
I'm going to walk you through some more examples,and this will help you see how this powerfulnew contextual collaboration is such a remarkableboost to productivity and creativity.Say you are writing to yourneighbors about an upcomingpotluck.Now, as you can see, Sidekick has summarizedwhat this conversation is about.Last year, everyone broughthummus.Who doesn't love hummus!But this year, you want a little more variety.Let's see what people signed upto bring.Now, somewhere in this thread isa Google sheet, where you'vecollected that information.You can get some help by typing,"Write a note about the maindishes people are bringing."And let's see what we get back.Awesome!It found the right sheet andcited the source, in the "Foundin" section, giving youconfidence that this is not madeup.Looks good.You can insert it directly intoyour E mail.Let's end with an example of howthis can help you at work.Say you are about to give animportant presentation, and you've been sofocused onthe content that you forgot toprepare speaker notes.The presentation is in an hour.Uh oh.No need to panic.Look at what one of thesuggestions is: Create speakernotes for each slide.
[Cheers and Applause].
Let's see what happens.What happened behind the scenes here is thatthe presentation and otherrelevant context is sentto the model to help createthese notes.Once you've reviewed them, youcan hit insert and edit thenotes to convey what youintended.So you can now deliver the presentation withoutworrying about the notes.As you can see, we've been having a ton offun playing with this.We can see the true potential ofAI as a collaborator, and willbe bringing this experience toDuet AI for Workspace.With that, I'll hand it back toSundar.
[Cheers and Applause].

>>SUNDAR: Thanks, Aparna.It's exciting to see all theinnovation coming to GoogleWorkSpace.As AI continues to improverapidly, we are focused ongiving helpful features to ourusers.And starting today, we aregiving you a new way to previewsome of the experiences acrossWorkSpace and other products.It's called Labs.I say new, but Google has a longhistory of bringing labs, and, you know, we'vemade it available throughout our history aswell.You can check it out at Google.com/labs.Next up, we're going to talk about Search.Search has been our founding product fromour earliest days.And we've always approached it placing usertrust about everything else.To give you a sense of how we are bringinggenerating AI on to search, I'm going to inviteCathy on to stage.Cathy.
[Cheers and Applause].

>>CATHY EDWARDS: Thanks, Sundar.I've been working on Search formany years, and what inspires me so much ishow it continues to be an unsolved problem,and that's why I'm just so excited by thepotential of bringing generative AI in toSearch.Let's give it a whirl.So let's start with a search for what's betterfor a family with kids under three and a dog,Bryce Canyon or Arches.Now, although this is thequestion you have, you probablywouldn't ask it in this waytoday.You'd break it down into smallerones, sift through information,and then piece things togetheryourself.Now, Search does the heavylifting for you.What you see here looks prettydifferent, so let me first giveyou a quick tour.You'll notice a new integratedsearch results page so you canget even more out of a singlesearch.There's an AI powered snapshotthat quickly gives you the layof the land on a topic.And so here you can see that while both parksare kid friendly, only Bryce Canyon has moreoptions for your furry friend.If you want to dig deeper, thereare links included in thesnapshot.You can also click to expandyour view.And you'll see how informationis corroborated, so you cancheck out more details and really explorethe richness of the topic.This new experience builds onGoogle's ranking and safetysystems that we've beenfine tuning for decades.Search will continue to be yourjumping off point to what makesthe Web so special, its diverserange of content, frompublishers to creators,businesses, and even people likeyou and me.So you can check outrecommendations from expertslike the National Park Service,and learn from authentic,first hand experiences like theMOM Trotter blog.Because even in a world where AIcan provide insights, we knowthat people will always valuethe input of other people, and athriving Web is essential tothat.These new generative AI
[Cheers and Applause].
Thank you!These new generative AIcapabilities will make Searchsmarter, and searching simpler.And as you've seen, this isespecially helpful when you needto make sense of somethingcomplex, with multiple angles toexplore.You know, those times when evenyour question has questions.So, for example, let's say you're searchingfor a good bike for a five mile commute withhills.This can be a big purchase.So you want to do some research.In the AI powered snapshot,you'll see importantconsiderations like motor andbattery for taking on thosehills, and suspension for acomfortable ride.Right below, you'll seeproducts that fit the bill, eachwith images, reviews, helpfuldescriptions and currentpricing.This is built on Google'sShopping Graph, the world's mostcomprehensive dataset ofconstantly changing products,sellers, brands, reviews andinventory out there, with over35 billion listings.In fact, there are 1.8 billionlive updates to our ShoppingGraph every hour.So you can shop with confidencein this new experience, knowingthat you'll get fresh, relevantresults.And for commercial queries likethis, we also know that ads canbe especially helpful to connect people withuseful information and help businesses getdiscovered online.They're here, clearly labeled,and we're exploring differentways to integrate them as weroll out new experiences inSearch.And now that you've done someresearch, you might want toexplore more.So right under the snapshot, you'll see theoption to ask a follow up question, or selecta suggested next step.Tapping any of these optionswill bring you into our brandnew conversational mode.
[Cheers and Applause].
In this case, maybe you want toask a follow up about eBikes, soyou look for one in yourfavorite color, red.And without having to go back tosquare one, Google Searchunderstands your full intent,and that you’re lookingspecifically for eBikes in redthat would be good for a fivemile commute with hills.And even when you're in thisconversational mode, it’s anintegrated experience, so youcan simply scroll to see othersearch results.Now, maybe this eBike seems tobe a good fit for your commute.With just a click, you'reable to see a variety ofretailers that have it in stock,and some that offer freedelivery or returns.You'll also see current prices,including deals, and canseamlessly go to a merchant'ssite, check out, and turn yourattention to what reallymatters, getting ready to ride.These new generative AIcapabilities also unlock a wholenew category of experiences onSearch.It could help you create aclever name for your cyclingclub, craft the perfect socialpost to show off your newwheels, or even test your knowledge on bicyclehand signals.These are things you may never have thoughtto ask Search for before.Shopping is just one example of where thiscan be helpful.Let's walk through another onein a live demo.What do you say?
[Cheers and Applause].
Yeah.So special shout out to mythree year old daughter, who is obsessed withwhales.I wanted to teach her aboutwhale songs, so let me go to the Google appand ask, why do whales like to sing?And so here I see a snapshot that organizationsthe Web results and gets me to key thingsI want to know so I can understand quicklythat oh, they sing for a lot of differentreasons, like to communicate with other whales,but also to find food.And I can click "see more" to expand hereas well.Now, if I was actually with my daughter, andnot on stage in front of thousands of people,I'd be checking out some of these Web resultsright now.They look pretty good.Now I'm thinking she would get akick out of seeing one up close,so let me ask, can I see whales in California?And so the LLMs right now are working behindthe scenes to generate my snapshot,distilling insights andperspectives from across theWeb.It looks like in northern California, I cansee humpbacks around this time of year.That's cool.I'll have to plan to take her on a trip soon.And again, I can see some reallygreat results from across the Web.And if I want to refer to theresults from my previousquestion, I can just scroll right up.Now, that's got a birthday coming up, so Ican follow up with plush ones for kids under$40.Again, the LLMs are organizing this informationfor me, and this process will get faster overtime.These seem like some great options.I think she'll really like the second one.She's in to Orcas as well.Phew!Live demos are always nerveracking.I'm really glad that one went whale!
[Cheers and Applause].
What you've seen today is just afirst look at how we'reexperimenting with generative AIin Search, and we're excited tokeep improving with yourfeedback through our Search LabsProgram.This new Search generativeexperience, also known as SGE,will be available in labs, alongwith some other experiments.And they'll be rolling out in the coming weeks.If you're in the U.S., you canjoin the wait list today by tapping the labsicon in the latest versions of the Googleapp or Chrome desktop.This new experience reflects thebeginning of a new chapter, andyou can think of this evolutionas Search, super charged.Search has been at the core ofour timeless mission for 25years.And as we build for the future, we're so excitedfor you to turn to Google for things you neverdreamed you could.Here's an early look at what'sto come for AI in Search.
[Music playing]
>> Hey!I'mma make'em talk like whoaMove fast, move slowCatch me on a rollCome say hello, 3 2 1 let's goYes.Yes.Yes!Come say hello, 3 2 1 let's go
>> You got this, let's go!
>> Is a hotdog a sandwich?And the answer is...
>> Yes.
>> No.
>> Yes!
>> No!
[Music playing]
>> I'mma make'em talk like whoa,whoa, whoa, whoa, whoa.I'mma make'em talk like.I'mma make'em talk like whoa.
[Cheers and Applause].

>>SUNDAR: Is a hotdog asandwich?I think it's more like a tacobecause the bread goes aroundit.
[Laughter].
That comes from the expertviewpoint of a vegetarian.
[Laughter].
Thanks, Cathy.It's so exciting to see how weare evolving Search and lookforward to building it with you.So far today, we have shared howAI can help unlock creativity,productivity and knowledge.As you can see, AI is not only apowerful enabler, it's also abig platform shift.Every business and organizationis thinking about how to drivetransformation.That's why we are focused onmaking it easy and scalable forothers to innovate with AI.That means providing the mostadvanced computinginfrastructure, includingstate of the art TPUs and GPUs,and expanding access to Google'slatest foundation models thathave been rigorously tested inour own products.We are also working to provideworld class tooling so customerscan train, fine tune and runtheir own models, withenterprise grade safety,security and privacy.To tell you more about how weare doing this with GoogleCloud, please welcome Thomas.
[Applause].

>>THOMAS KURIAN: All of the AIinvestments you've heard abouttoday are also coming tobusinesses.So whether you're an individualdeveloper or a full scaleenterprise, Google is using thepower of AI to transform the wayyou work.There are already thousands ofcompanies using our generativeAI platform to create amazingcontent, to synthesize andorganize information, toautomate processes, and to build incrediblecustomer experiences.And yes, each and every one of you can, too.There are three ways Google Cloud can helpyou take advantage of the massive opportunityin front of you.First, you can quickly buildgenerative applications usingour AI platform, Vertex AI.With Vertex you can accessfoundation models for chat, textand image.You just select the model youwant to use, create prompts totune the model, and you can evenfine tune the model's weights onyour own dedicated computeclusters.To help you retrieve fresh andfactual information from yourcompany's databases, your corporate internet,your Web site and enterprise applications,we offer Enterprise Search.Our AI platform is so compellingfor businesses because itguarantees the privacy of yourdata.With both Vertex and Enterprise Search, youhave sole control ofyour data and the costs of usinggenerative AI models.In other words, your data isyour data, and no one else's.You can also choose the bestmodel for your specific needsacross many sizes that have beenoptimized for cost, latency andquality.Many leading companies are usingour generative AI technologiesto build super coolapplications, and we've beenblown away by what they'redoing.Let's hear from a few of them.
>>AMJAD MASAD: The unique thingabout Google Cloud is theexpansive offering.
>>TODD PENEGOR: The Googlepartnership has taught us tolean in, to iterate, to test andlearn and have the courage tofail fast where we need to.
>>STEVE JARRETT: But also Googleis a really AI centric company,and so there's a lot for us tolearn directly from theengineering team.
>>BERND LEUKERT: Now withgenerative AI, you can have amuch smarter conversation withour customers
>>MEL PERKINS: We have beenreally enjoying taking thelatest and greatest technologyand making that accessible toour entire community.
>>KAMRAN ZARGAHI: Getting earlyaccess to Vertex APIs opens alot of doors for us to be mostefficient and productive in theway we create experiences forUber customers.
>>AMJAD MASAD: The act of makingsoftware is really suddenly openup to everyone.Now you can talk to the AI onthe Replit app and tell it,“Make me a workout program.”And with one click, we candeploy it to a Google Cloud VMand you have an app that youjust talked into existence.
>>MEL PERKINS: We have anextraordinarily exciting featurein the pipeline.It’s called Magic Video, and itenables you to take your videosand images, and with just acouple of clicks, turn that intoa cohesive story.It is powered by Google's PaLMtechnology, and it trulyempowers everyone to be able tocreate a video with absoluteease.
>>TODD PENEGOR: Folks come to aWendy's, and a lot of times theyuse some of our acronyms.The Junior Bacon Cheeseburger,they'll come in and, “Give me aJBC.”We need to understand what thatreally means, and voice AI canhelp make sure that order isaccurate every single time.
>>BERND LEUKERT: Generative AIcan be incorporated in all thebusiness processes Deutsche Bankis running.
>>TODD PENEGOR: The partnershipwith Google has inspired us toleverage technology, to trulytransform the whole restaurantexperience.
>>BERND LEUKERT: There is nolimitations.
>>AMJAD MASAD: There's no otherway to describe it.Google's just living in the future.
[Applause].

>>THOMAS KURIAN: We're also doing this withpartners likeCharacter AI.We provide Character with theworld's most performant andcost efficient infrastructurefor training and serving theirmodels.By combining its own AIcapabilities with those ofGoogle Cloud, consumers cancreate their own deeplypersonalized characters andinteract with them.We're also partnering withSalesforce to integrate GoogleCloud's AI models and Big Querywith their data cloud andEinstein, their AI infused CRMassistant.In fact, we are working withmany other incredible partners,including consultancies,software as a service leaders,consumer internet companies tobuild remarkable experienceswith our AI technologies.In addition to PaLM 2, we areexcited to introduce three newmodels in Vertex, includingImagine, which powers imagegeneration editing andcustomization from text inputs.Codey for code completion andgeneration, which you can trainon your own code base to helpyou build applications faster,and Chirp, a universal speechmodel which bringsspeech to text accuracy for over300 languages.We're also introducingReinforcement Learning FromHuman Feedback into Vertex AI.You can fine tune pre trainedmodels by incorporating humanfeedback to further improve themodel's results.You can also fine tune a modelon domain or industry specificdata, as we have with Sec PaLMand Med PaLM, so they becomeeven more powerful.All of these features are now inpreview, and I encourage each and every oneof you to try them.
[Cheers and Applause].
The second way we're helping youtake advantage of thisopportunity is by introducingDuet AI for Google Cloud.Earlier, Aparna told you aboutDuet AI for Google Workspace andhow it is an always on AIcollaborator to help people getthings done.Well, the same thing is true with Duet AIfor Google Cloud, which serves as an AI expertpair programmer.Duet uses generative AI toprovide developers assistance wherever youneed it within the IDE, the Cloud console,or directly within chat.It can provide contextual codecompletion, offer suggestionstuned to your code base,And generate entire functions in real time.It can even assist you with code reviews andcode inspection.Chen will show you more in thedeveloper keynote.The third way we are helping youseize this moment is by buildingall of these capabilities on our AI optimizedinfrastructure.This infrastructure makeslarge scale training workloadsup to 80 percent faster, and upto 50 percent cheaper comparedto any alternatives out there.Look, when you nearly double performance
[Applause].
When you nearly doubleperformance for less than halfthe cost, amazing things canhappen.Today, we are excited toannounce a new addition to thisinfrastructure family, the A3Virtual Machines based onNVIDIA's H100 GPUs.We provide the widest choice ofcompute options for leading AIcompanies like Anthropic andMidjourney to build their futureon Google Cloud.And yes, there's so much more to come.Next, Josh is here to show youexactly how we're making it easyand scalable for every developerto innovate with AI and PaLM 2.
[Cheers and Applause].

>>JOSH WOODWARD: Thanks, Thomas.Our work is enabling businessesand it's also empoweringdevelopers.PaLM 2, our most capable nextgeneration language model thatSundar talked about, powers thePaLM API.Since March, we've been runninga private preview with our PaLM API, and it'sbeen amazing to see how quickly developershave used it in their applications.Like CHAPTR, who are generatingstories so you can choose yourown adventure, forever changingstorytime.Or GameOn Technology, a companythat makes chat apps for sportsfans and retail brands toconnect with their audiences.And there's also Wendy's.They're using the PaLM API to help customersplace that correct order for the junior baconthey talked about in their talk to menu feature.But I'm most excited by theresponse we've gotten fromthe developer tools community.Developers want choice when itcomes to language models, and we're workingwithworking with LangChain, Chroma,and many more to add PaLM APIWe've also integrated intoGoogle developer tools likeFirebase and Colab.
[Cheers and Applause].
You can hear a lot more aboutthe PaLM API in the DeveloperKeynote, and sign up today.Now, to show you just how powerful the PaLMAPI is, I want to share one concept that fiveengineers at Google put together over thelast few weeks.The idea is called ProjectTailwind, and we think of it asan AI first Notebook that helpsyou learn faster.Like a real notebook, your notesand your sources power Tailwind.How it works is you can simply pick the filesfrom Google Drive and it effectively createsa personalized and private AI model that hasexpertise in the information that you giveit.We've been developing this ideawith authors like StevenJohnson, and testing it atuniversities like Arizona Stateand the University of Oklahoma,where I went to school.Do you want to see how it works?Let's do a live demo.Now, imagine that I'm a studenttaking a computer history class.I open up tailwind, and I can quickly seeall my different notes, assignments and reading.I can insert them and what will happen whenTailwind loads up is you can see my differentnotes and articles on the side.Here they are in the middle, and it instantlycreates a study guide on the right to giveme bearings.You can see it's pulling out key conceptsand questions, grounded in the materials thatI've given it.Now, I can come over here and quickly changeit to go across all the different sources,and type something like, create glossary forhopper.And what's going to happen behind the scenesis it will automatically compile a glossaryassociated with all the different notes andarticles relating to Grace Hopper, the computerscience history pioneer.Look at this.Flowmatic, Coval, Compiler, all created basedon my notes.Now, let's try one more.I'm going to try something else called differentviewpoints on Dynabook.So the Dynabook, this was a concept from AlanKay.Again, Tailwind, going out, finding all thedifferent things.You can see how quickly it comes back.There it is.And what's interesting here is it's helpingme think through the concepts so it's givingme different viewpoints.It was a visionary product.It was a missed opportunity.But my favorite part is it shows its work.You can see the citations here.When I hover over, here's something from myclass notes.Here's something from an article the teacherassigned.It's all right here, grounded in my sources.
[Cheers and Applause].
Now, Project Tailwind is still in its earlydays, but we've had so much fun making thisprototype, and we realized it's not just forstudents.It's helpful for anyone synthesizing informationfrom many different sources that you choose.Like writers researching anarticle, or analysts goingthrough earning calls, or evenlawyers preparing for a case.Imagine collaborating with an AIthat's grounded in what you'veread and all your notes.We want to make it available to try it outif you want to see it.
[Cheers and Applause].
There's a lot more you can do with PaLM 2,and we can't wait to see what you build usingthe PaLM API.Because generative AI ischanging what it means todevelop new products.At Google, we offer the best MLinfrastructure, with powerfulmodels including those inVertex, and APIs and tools toquickly generate your ownapplications.And building bold AI alsorequires a responsible approach,so let me hand it over to Jamesto share more.Thanks.
[Cheers and Applause].

>>JAMES MANYIKA: Hi, everyone.I'm James.In addition to Research, I leada new area at Google called Technology andSociety.Growing up in Zimbabwe, I couldnot have imagined all theamazing and ground breakinginnovations that have been presented on thisstage today.And while I feel it's importantto celebrate the incredible progress in AIand the immense potential it has for peoplein society everywhere, we must also acknowledgethat it's an emerging technology that is stillbeing developed, and there's still so muchmore to do.Earlier, you heard Sundar saythat our approach to AI must beboth bold and responsible.While there is a natural tensionbetween the two, we believe it'snot only possible, but, in fact, criticalto embrace that tension productively.The only way to be truly bold inthe long term is to beresponsible from the start.Our field defining research ishelping scientists make boldadvances in many scientificfields, including medicalbreakthroughs.Take, for example, GoogleDeepMind's AlphaFold program,which can accurately predict the3D shapes of 200 millionproteins.That's nearly all the catalogedproteins known to science.AlphaFold gave us the equivalentof nearly 400 million years ofprogress in just weeks.
[Applause].
So far, more than one millionresearchers around the worldhave used AlphaFold'spredictions, including FengZhang's pioneering lab at theBroad Institute of MIT andHarvard.In fact, in March this year, Zhang and hiscolleagues at MITannounced they used AlphaFold todevelop a novel molecularsyringe which could deliverdrugs to help improve theeffectiveness of treatments fordiseases like cancer.
[Cheers and Applause].
While it's exhilarating to seesuch bold and beneficialbreakthroughs, AI also has the potential toworsen existingsocietal challenges like unfairbias, as well as pose newchallenges as it becomes moreadvanced, and new uses emerge.That's why we believe it'simperative to take a responsibleapproach to AI.This work centers around our AIPrinciples that we firstestablished in 2018.These principles guide productdevelopment, and they help usassess every AI application.They prompt questions like,"will it be sociallybeneficial?"Or, "could it lead to harm inany way?"One area that is top of mind forus is misinformation.Generative AI makes it easierthan ever to create new content.But it also raises additionalquestions aboutits trust worthiness.This is why we're developing andproviding people with tools toevaluate online information.For example, have you comeacross a photo on a Web site, orone shared by a friend, withvery little context, like thisone of the moon landing, andfound yourself wondering, isthis reliable?I have.And I'm sure many of you have aswell.In the coming months, we areadding two new ways for peopleto evaluate images.First, with our "About thisImage" tool in Google Search.You will be able to seeimportant information such aswhen and where similar imagesmay have first appeared, whereelse the image has been seenonline, including news, factand social sites, all this providing you withhelpful context to determine if it's reliable.Later this year, you'll also beable to use it if you search foran image or screenshot usingGoogle Lens, or when you're onwebsites in Chrome.And as we begin to roll outgenerative image capabilities,like Sundar mentioned, we willensure that every one ofour AI generated images hasmetadata, a markup in theoriginal file, to give youcontext if you come across itoutside of our platforms.Not only that, Creators andPublishers will be able to addsimilar metadata, so you'll beable to see a label in images inGoogle Search, marking them asAI generated.
[Applause].
As we apply our AI principles,we also start to see potentialtensions when it comes to beingbold and responsible.Here is an example.Universal Translator is anexperimental AI video dubbingservice that helps expertstranslate a speaker's voicewhile also matching their lipmovements.Let me show you how it workswith an online college course,created in partnership withArizona State University.
>> What many college studentsdon't realize is that knowingwhen to ask for help, and thenfollowing through on usinghelpful resources is actually ahallmark of becoming aproductive adult.
[Foreign language].

[Cheers and Applause].

>>JAMES MANYIKA: We use next generation translationmodels to translate what the speaker is saying,models to replicate the style and the tone,and then match the speaker's lip movements,and then we bring it all together.This is an enormous step forwardfor learning comprehension, andwe're seeing promising resultswith course completion rates.But there's an inherent tensionhere.You can see how this can beincredibly beneficial, but someof the same underlyingtechnology could be misused by bad actorsto create deep fakes.So we've built this service with guardrailsto help prevent misuse and, we make it accessibleonly to authorized partners.
[Cheers and Applause].
And, as Sundar mentioned, soonwe'll be integrating our newinnovations in watermarking intoour latest generative models toalso help with the challenge ofmisinformation.Our AI principles also helpguide us on what not to do.For instance, years ago, we werethe first major company todecide not to make ageneral purpose facialrecognition API commerciallyavailable.We felt there weren't adequatesafeguards in place.Another way we live up to our AIprinciples is with innovationsto tackle challenges as theyemerge, like reducing the riskof problematic outputs that maybe generated by our models.We are one of the first in theindustry to develop and launchautomated adversarial testingusing large language modeltechnology.We do this for queries likethis, to help us uncover andreduce inaccurate outputs, likethe one on the left, and makethem better, like the one on theright.We're doing this at a scalethat's never been done before atGoogle, significantly improvingthe speed, quality and coverageof testing, allowing safetyexperts to focus on the mostdifficult cases.And we're sharing theseinnovations with others.For example, our "PerspectiveAPI", originally created to helppublishers mitigate toxicity isnow being used in large languagemodels.Academic researchers have usedour perspective API to create an industryevaluation standard.And today, all significant largelanguage models, including thosefrom OpenAI and Anthropic,incorporate this standard toevaluate toxicity generated bytheir own models.
[Applause].
Building AI responsibly must bea collective effort involvingresearchers, social scientists,industry experts, governmentsand everyday people, as well ascreators and publishers.Everyone benefits from a vibrantcontent ecosystem.Today and in the future.That's why we're gettingfeedback and will be workingwith the Web community on waysto give publishers choice andcontrol over their Web content.It's such an exciting time.There's so much we can accomplish, and somuch we must get right together.We look forward to working withall of you.And now I'll hand it off toSameer, who will speak to youabout all the excitingdevelopments we're bringing toAndroid.Thank you.
[Cheers and Applause].

>>SAMEER: Hi, everyone!It's great to be back at GoogleI/O.As you've heard today, our boldand responsible approach to AIcan unlock people's creativityand potential.But how can all this helpfulnessreach as many people aspossible?At Google, our computingplatforms and hardware productshave been integral to thatmission.From the beginning of Android,we believed that an open OSwould enable a whole ecosystemand bring smartphones toeveryone.And as we all add more devicesto our lives, like tablets, TVs,cars and more, this opennesscreates the freedom to choosethe devices that are best foryou.With more than three billionAndroid devices, we've now seenthe benefits of using AI toimprove experiences at scale.For example, this past year,Android used AI models toprotect users from more than 100billion suspected spam messagesand calls.
[Cheers and Applause].
We can all agree, that's pretty useful!There are so many opportunitieswhere AI can just make thingsbetter.Today, we'll talk about two bigways Android is bringing thatbenefit of computing toeveryone.First, continuing to connect youto the most complete ecosystemof devices, where everythingworks better together.And second, using AI to makethings you love about Androideven better, starting withcustomization and expression.Let's begin by talking aboutAndroid's ecosystem of devices,starting with two of the mostimportant: Tablets and watches.Over the last two years, we'veredesigned the experience onlarge screens, including tabletsand foldables.We introduced a new system formulti tasking that makes it somuch easier to take advantage ofall that extra screen realestate and seamlessly movebetween apps.We've made huge investments tooptimize more than 50 Googleapps, including G mail, photosand meet.And we're working closely withpartners such as Minecraft,Spotify and Disney+ to buildbeautiful experiences that feelintuitive on larger screens.People are falling in love withAndroid tablets and there aremore great devices to pick fromthan ever.Stay tuned for our hardwareannouncements, where you justmight see some of the awesomenew features we're building fortablets in action.It's really exciting to see the
[Cheers and Applause].
It's really exciting to see themomentum in smart watches aswell.WearOS is now thefastest growing watch platform,just two years after launchingWearOS 3 with Samsung.A top ask from fans has been formore native messaging apps onthe watch.I'm excited to share thatWhatsApp is bringing theirfirst ever watch app to Wearthis summer.
[Cheers and Applause].
I'm really enjoying usingWhatsApp on my wrist.I can start a new conversation,reply to messages by voice andeven take calls.I can't wait for you to try it.Our partnership on WearOS withSamsung has been amazing, andI'm excited about our newAndroid collaboration onimmersive XR.We'll share more later thisyear.Now, we all know that to get thebest experience, all thesedevices need to work seamlesslytogether.It's got to be simple.That's why we built Fast Pair,which lets you easily connectmore than 300 headphones.And it's why we have NearbyShare to easily move filesbetween your phone, tablet orwindows in Chrome OS computer.And Cast, to make streamingvideo and audio to your devicesultra simple, with support forover 3,000 apps.It's great to have all of ourdevices connected, but if you'reanything like me, it can be hardto keep track of all the stuff.Just ask my family.I misplace my earbuds at leastthree times a day, which is whywe're launching a major updateto our Find My Device experienceto support a wide range ofdevices in your life, includingheadphones, tablets and more.It's powered by a network ofbillions of Android devicesaround the world, so if youleave your earbuds at the gym,other nearby Android devices canhelp you locate them.And for other important thingsin your life, like your bicycleor suitcase, Tile, Chipolo, andothers, will have tracker tagsthat work with the Find MyDevice Network as well.
[Cheers and Applause].
Now, we took some time to reallyget this right, becauseprotecting your privacy andsafety is vital.From the start, we designed thenetwork in a privacy preservingway, where location informationis encrypted.No one else can tell where yourdevices are located, not evenGoogle.This is also why we areintroducing Unknown TrackerAlerts.Your phone will tell you if anunrecognized tracking tag ismoving with you, and help youlocate it.
[Cheers and Applause].
It's important that thesewarnings work on your Androidphone, but on other types ofphones as well.That's why last week, we published a new industrystander with Apple, outlining how unknowntracker alerts will work across all smartphones.
[Cheers and Applause].
Both the new Find My Deviceexperience and Unknown TrackerAlerts are coming later thissummer.
[Applause].
Now, we've talked a lot aboutconnecting devices, but Androidis also about connecting people.After all, phones were createdfor us to communicate with ourfriends and family.When you are texting in a groupchat, you shouldn't have toworry about whether everyone isusing the same type of phone.Sending high quality images andvideo, getting typingnotifications and end to endencryption should all just work.That's why we've worked with ourpartners on upgrading old SMSand MMS technology to a modernstandard called RCS.That makes all of this possible,and there are now over 800million people with RCS.On our way to over a billion by the end ofthe year.We hope every mobile operatingSystem 
[Laughter] 
gets the message and adoptsRCS.
[Cheers and Applause].
So we can all hang out in thegroup chat together, no matterwhat device we're using.Whether it's connecting withyour loved ones or connectingall of your devices, Android'scomplete ecosystem makes iteasy.Another thing people love aboutAndroid is the ability tocustomize their devices andexpress themselves.Here's Dave to tell you how weare taking this to the nextlevel with generative AI.
[Applause].

>>DAVE: Thanks, Sameer.And hello, everyone.So here's the thing.People want to expressWith Google's advances in generative AI soyour phone can feel even more personal.So let me show you what this looks like.To start, messages and conversation can beso much more expressive, fun and playful withMagic Compose.It's a new feature coming toGoogle Messages powered bygenerative AI that helps you addthat extra spark of personalityto your conversation.Just type your message like younormally would, and choose howyou want to sound.Magic Compose will do therest.So your messages give off morepositivity, more rhymes, moreprofessionalism.Or if you want, in the style ofa certain playwright.To try or not to try thisfeature, that is the question.Now, we also have newpersonalizations coming to theOS layer.At Google I/O two years ago, weintroduced Material You.It's a design system whichcombines user inspiration withdynamic color science for afully personalized experience.We're continuing to expand onthis in Android 14 with all newcustomization options coming toyour lockscreen.Now, I can add my ownpersonalized style to thelockscreen clock so that itlooks just the way I want.And what's more, with the newcustomizable lockscreenshortcuts, I can instantly jumpin to my most frequentactivities.Of course, what really makesyour lockscreen and home screenyours is the wallpaper, and it'sfirst thing that many of usset when we get a new phone.Now, emojis are such a fun andsimple way of expressingyourself so we thought wouldn'tit be cool to bring them to yourwallpaper?With Emoji wallpapers, you canchoose your favorite combinationof emojis, pick the perfectpattern, and find just the rightcolor to bring it all together.So let's take a look.And I'm not going to use the laptops.I'm going to use a phone.All right.So let's see.I'm going to go into the wallpaper picker,and I'm going to tap on the new option foremojis.And I'm feeling in a kind of, I don't know,zany mood, with all you people looking atme, so I'm going to pick this guy and thisguy, and let's see, who else is in here?This one looks pretty cool.I like the ape fit one, and obviously thatone.And somebody said there was a duck on stageearlier, so let's go find a duck.Hello, duck.Where's the duck.Anyone see a duck?Where's the duck?There's the duck.All right.There it is.We got some ducks.Okay.Cool.And then pattern wise, we got a bunch of differentpatterns you can pick.I'm going to pick mosaic.That's my favorite.I'm going to play with the Zoom.Let's see.We'll get this just right.Okay.I got enough ducks in there.Okay.Cool.And then colors, let's see, ooh, let's gowith the more muted one.That one.No, that looks good.I like that one.All right.Select that, set the wallpaper, and then Igo, boom!Looks pretty cool, huh?
[Cheers and Applause].
And the little emojis, they react when youtap them, which I find unusually satisfying.How much time have I got?Okay.Now, of course, so many of us like to usea favorite photo for our wallpaper, and sowith the new cinematic wallpaper feature youcan create a stunning 3D image from any regularphoto and then use it as your wallpaper.So let's take a look.So this time I'm going to go into my photos.And I really like this photo of my daughter,so let me select that.And you'll notice there's a sparkle icon atthe top.So if I tap that, I then get anoption for cinematic wallpaper.So let me tap that, and wait for it.Boom.Now, under the hood, we're usingan on device convolutionalneural network to estimatedepth, and a generativeadversarial network forinpainting as the backgroundmoves.The result is a beautifulcinematic 3D photo.So now let me set the wallpaper.And then I'm going to return home.And check out the parallaxeffect as I tilt the device.It literally jumps off thescreen.
[Cheers and Applause].
Both Cinematic Wallpapers andEmoji Wallpapers are comingfirst to Pixel devices nextmonth.
[Cheers and Applause].
So let's say you don't havethe perfect wallpaper photohandy, or you just want to havefun and create something new.With our new Generative AIwallpapers, you choose whatinspires you, and we create abeautiful wallpaper to fit yourvision.So let's take a look.So this time, I'm going to go and select createa wallpaper with AI.And I like classic art, so let me tap that.Now, you'll notice at the bottom we use structuredprompts to make it easier to create.So for example, I can pick what am I goingto do?City by the bay in a post impressionist style.Cool.And I type tap create wallpaper.Nice.Now, behind the scenes, we'reusing Google's text to imagediffusion models to generatecompletely new and originalwallpapers.And I can swipe through and seedifferent options that it's created.And some of these look really cool, right?
[Applause].
So let me pick this one.I like this one.So I'll select that.Set the wallpaper.And then return home.Cool.So now, out of billions of Android phonesin the world, noother phone will be quite likemine.And thanks to Material You, youcan see the system's colorpalette automatically adapts tomatch the wallpaper I created.Generative AI Wallpapers will becoming this fall.
[Cheers and Applause].
So from a thriving ecosystem ofdevices to AI poweredexpression, there's so muchgoing on right now in Android.Okay.Rick is up next to show you howthis Android innovation iscoming to life in the Pixelfamily of devices.Thank you.
[Cheers and Applause].

>>RICK OSTERLOH: The pace of AIinnovation over the past yearhas been astounding.As you heard Sundar talk about earlier, newadvances are transforming everything fromcreativity and productivity to knowledge andlearning.Now, let's talk about what thatinnovation means for Pixel,which has been leading the wayin AI driven hardwareexperiences for years.Now, from the beginning, Pixel was conceivedas an AI first mobile computer, bringing togetherall the amazing breakthroughs across the company,and putting them in to a Google device youcan hold in your hand.Other phones have AI features,but Pixel is the only phone withAI at the center.And I mean that literally.The Google Tensor G2 chip iscustom designed to put Google'sleading edge AI research to workin our Pixel devices.By combining Tensor's on deviceintelligence with Google's AI inthe cloud, Pixel delivers trulypersonal AI.Your device adapts to your ownneeds and preferences, andanticipates how it can help yousave time and get more done.This Personal AI enables allthose helpful experiences that Pixel is knownfor that aren't available on any other mobiledevice.on any other mobile device.Like pixel Call Assist, whichhelps you avoid long hold times,navigate phone tree menus,ignore the calls you don't wantand get better sound quality onthe calls you do want.
[Laughter].
Personal AI also enables helpfulPixel Speech capabilities.On device machine learningtranslates different languagesfor you, transcribesconversations in real time, andunderstands how you talk andtype.And you're protected with PixelSafe, a collection of featuresthat keep you safe online and in the realworld.And of course, there's PixelCamera
[Cheers and Applause].
It understands faces, expressions and skintones tobetter depict you and the peopleyou care about, so your photoswill always look amazing.We're also constantly working tomake Pixel Camera more inclusiveand more accessible, withfeatures like Real Tone andGuided Frame.
[Cheers and Applause].
Pixel experiences continue to becompletely unique in mobilecomputing, and that's becausePixel is the only phoneengineered end to end by Google,and the only phone that combinesGoogle Tensor, Android and AI.
[Cheers and Applause].
With this combination ofhardware and software, Pixellets you experience all thoseincredible new AI poweredfeatures you saw today in oneplace.For example, the new MagicEditor in Google Photos thatSundar showed you will beavailable for early access toselect Pixel phones later thisyear, opening up a whole newavenue of creativity with yourphotos.Dave just showed you how Androidis adding depth to how you canexpress yourself with newGenerative AI wallpapers, andacross Search, Workspace andBard, new features powered bylarge language models can sparkyour imagination, make big tasksmore manageable, and help youfind better answers to everydayquestions, all from your Pixeldevice.We have so many more excitingdevelopments in this space.And we can't wait to show you more in thecoming months.Now, it's probably no surprise that as AIkeeps getting more and more helpful, our Pixelportfolio keeps growing in popularity.Last year's Pixel devices are our most populargeneration yet, with both users and respectedreviewers and analysts.
[Applause].
Our Pixel phones won multiplePhone of the Year awards.
[Cheers and Applause].
Yes.Thank you.And in the premium smartphonecategory, Google is thefastest growing OEM in ourmarkets.
[Cheers and Applause].
One of our more popular productsis the Pixel A series, whichdelivers incredible
[Cheers and Applause].

>> Thank you.I'm glad you like it.It delivers incredible Pixel performance ina very affordable device.And to continue the I/Otradition, let me show you thenewest member of our A series.
[Cheers and Applause].
Today, we're completelyupgrading everything you loveabout our A series with thegorgeous new Pixel 7a.
[Cheers and Applause].
Like all Pixel 7 series devices,the Pixel 7a is powered by ourflagship Google Tensor G2 chip,and it's paired with eight gigabytes of ram,which ensures Pixel 7a delivers best in classperformance and intelligence.And you're going to love thecamera.The 7a takes the crown from 6aas the highest rated camera inits class, with the biggestupgrade ever to our A seriescamera hardware, including a 72percent bigger main camerasensor.
[Applause].
Now, here's the best part.Pixel 7a is available today, starting at $499.
[Cheers and Applause].
It's an unbeatable combinationof design, performance andphotography, all at a great value.You can check out the entirePixel 7a lineup on the GoogleStore, including our exclusiveCoral color.Now, next up, we're going to show you howwe're continuing to expand the Pixel portfoliointo new form factors.
[Cheers and Applause].
Yeah.Like foldables and tablets.
[Cheers and Applause].
You can see them right there.It's a complete ecosystem of AI powered devicesengineered by Google.Here's Rose to share what alarger screen Pixel can do foryou.
[Applause].

>>ROSE: Okay.Let's talk tablets.Which have been a little bitfrustrating.It has always been hard to knowwhere they fit in, and theyhaven't really changed the pastten years.A lot of the time, they aresitting, forgotten in a drawer,and that one moment youneed it, it is out of battery.
[Laughter].
We believe tablets, and largescreens in general, still have alot of potential.So we set out to build somethingdifferent, making biginvestments across Google apps,Android and Pixel, to reimaginehow large screens can deliver amore helpful experience.Pixel Tablet is the only tabletengineered by Google anddesigned specifically to behelpful in your hand and in theplace they are used the most,the home.We designed the Pixel Tablet touniquely deliver helpful Pixel experiences,and that starts with great hardware.A beautiful 11 inch,high resolution display withcrisp audio from the fourbuilt in speakers.A premium aluminum enclosurewith a nanoceramic coating thatfeels great in the hand and iscool to the touch.The world's best Androidexperience on a tablet, poweredby Google Tensor G2, forlong lasting battery life andcutting edge personal AI.For example, with Tensor G2, weoptimize the Pixel Cameraspecifically for video calling.Tablets are fantastic videocalling devices.And with Pixel Tablet, you arealways in frame, in focus andlooking your best.The large screen makes PixelTablet the best Pixel device forediting photos, with AI poweredtools like Magic Eraser, andPhoto Unblur.Now, typing on a tablet can beso frustrating.With Pixel Speech and Tensor G2,we have the best voicerecognition, making voice typingnearly three times faster thantapping.And as Sameer mentioned, we'vebeen making huge investments tocreate great app experiences forlarger screens, including morethan 50 of our own apps.With Pixel tablet, you'regetting great tablet hardwarewith great tablet apps, but wesaw an opportunity to make thetablet even more helpful in thehome.So we engineered a first of itskind charging speaker dock.
[Cheers and Applause].
It gives the tablet a home.And now, you never have to worryabout it being charged.Pixel Tablet is always ready tohelp, 24/7.When it's docked, the new HubMode turns Pixel Tablet into abeautiful digital photo frame, apowerful smart home controller,a voice activated helper, and ashared entertainment device.It feels like a smart display,but it has one huge advantage.With the ultra fast fingerprintsensor, I can quickly unlock thedevice and get immediate accessto all of my favorite Androidapps.So I can quickly find a recipewith Side Chef, or discover anew podcast on Spotify, or findsomething to watch with thetablet optimized Google TV app.Your media is going to look andsound great with room fillingsound from the charging speakerdock.Pixel Tablet is also theultimate way to control yoursmart home.And that starts with the new,redesigned Google Home App.It looks great on Pixel Tablet,and it brings together over80,000 supported smart homedevices, including all of yourMatter Enabled devices.
[Cheers and Applause].
We also made it really easy toaccess your smart home controlsdirectly from Hub Mode.With the new home panel, anyfamily member can quickly adjustthe lights, lock the doors orsee if a package was delivered.Or, if you're lazy, like me, youcan just use your voice.Now, we know that tablets areoften shared, so a tablet forthe home needs to supportmultiple users.Pixel Tablet makes switchingbetween users super easy, so you get yourown apps and your own content while maintainingyour privacy.
[Cheers and Applause].
And my favorite part, it is soeasy to move content betweendevices.Pixel Tablet is the first tabletwith Chromecast built in, sowith a few taps
[Applause].
I can easily cast some music or my favoriteshow from the phone to the tablet.And then I can just take the tablet off thedock and keep listening or watching all aroundthe house.We designed a new type of casefor Pixel Tablet that solves thepain of flimsy tablet cases.It has a built in stand thatprovides continuous flexibilityand is sturdy at all angles, soyou can confidently use yourtablet anywhere, on a plane, inbed or in the kitchen.The case easily docks, so younever have to take it off tocharge.It's just another example of howwe can make the tabletexperience even more helpful.
[Cheers and Applause].
The new Pixel Tabletcomes in three colors.It is available for pre ordertoday and ships next month, starting at just$499.
[Applause].
And the best part, every Pixel Tablet comesbundled with a $129 charging speaker dockfor free!
[Cheers and Applause].
It is truly the best tablet inyour hand and in your home.To give you an idea of just howhelpful Pixel Tablet can be, weasked TV personality MichelleButeau to put it to the test.Let's see how that went.
>>MICHELLE BUTEAU: When Googleasked me to spend the day withthis tablet, I was a littleapprehensive, because I'm not atech person.I don't know how things work allthe time.But I'm a woman in STEM now.Some days I could barely findthe floor, let alone the chargerfor something, so when theGoogle folks said somethingabout a tablet that docks, I waslike, okay then, Google, proveit!
[Music playing].

[Laughter].
I'm on average two to fivemeetings a day.Today I got stuck on all thesefeatures, honey, the 360 of itall!The last time I was around thismuch sand, some of it got caughtin my belly button, and I had apearl two weeks later.Look, it's a bird!So this is what I love about myme time today.Six shows just popped up basedoff of my preferences.And they were like, hey, girl!
[Laughter].
I would have made it funnier,but that was good.My husband is actually aphotographer, so I have to relyon him to make everything niceand pretty.But now, I love this picture ofme and my son, but there's aboom mic there.Look.It's right here.You see this one?Get this mic.You see that?Magic Eraser, I can circle orbrush.I'm going to do both.Boom!How cute is that!And so I hope not only you guysare happy with me reviewingthis, but that you'll also giveme one, because, I mean
[Laughter].
You're getting tired, right?
>> No, I'm not!
>> You're not?Okay.'Cause I am.
[Applause].

>>RICK: That's a pretty goodfirst review.Now, tablets aren't the onlylarge screen device we want toshow you today.It's been really exciting to see foldablestake off over the past few years.Android's driven so muchinnovation in this newform factor, and we seetremendous potential here.We've heard from our usersthat the dream foldable shouldhave a versatile form factor,making it great to use bothfolded and unfolded.It should also have aflagship level camera system that truly takesadvantage of the unique design.And an app experience that'sfluid and seamless across bothscreens.Creating a foldable like thatit really means pushing the envelope withstate of the art technology, and that meansan ultra premium $1799 device.Now, to get there, we've beenworking closely with our Androidcolleagues to create a new standard for foldabletechnology.Introducing Google Pixel Fold.
[Cheers and Applause].
It combines Tensor G2 Androidinnovation and AI for anincredible phone that unfoldsinto an incredible compacttablet.It's the only foldableengineered by Google to adapt tohow you want to use it, with afamiliar front display thatworks great when it's folded,and when it's unfolded, it's our thinnestphone yet and the thinnest foldable on themarket.
[Applause].
Now, to get there, we had to pack a flagshiplevel phone into nearly half the thickness,which meant completely redesigning componentslike the telephoto lens and the battery, anda lot more.So it can fold up and it can fit in your pocket,and retain that familiar smartphone silhouettewhen it's in your hand, but Pixel Fold hasthree times the screen space of a normal phone.You unfold it and you're treated to an expansiveI 7.6 inch display that opens flat with acustom 180 degree fluid friction hinge.So you're getting the best of both worlds.It's a powerful smartphone when it's convenientand an immersive tablet when you need one.And like every phone we make, Pixel Fold isbuilt to last.We've extensively tested thehinge to be the most durable ofany foldable.Corning Gorilla Glass Victusprotects it from exteriorscratches, while the IPX8 waterresistant design safeguardsagainst the weather.And as you'd expect from a Pixeldevice, Pixel Fold gives youentirely new ways to takestunning photos and videos withPixel Camera.Put the camera in tabletopmode to capture the stars.And you can get closer with the best zoomon a foldable.And use the best camera on thephone for your selfies.The unique combination of formfactor, triple rear camerahardware, and Personal AI withTensor G2 make it the bestfoldable camera system.
[Cheers and Applause].
Now, there are so many experiences that feeleven more natural with a Pixel fold.One is the Dual Screen Interpreter Mode.Your Pixel Fold can use both displays, bothdisplays, toprovide a live translation toyou and the person you're talking to.So it's really easy to connect across languages.
[Applause].
And powering all of this is Google TensorG2.Pixel Fold has all of thePersonal AI features you wouldexpect from a top of the linePixel device, across safety,speech and call assist.Plus, great performance foron the go multi tasking andentertainment.And the entire foldableexperience is built on Android.Let's get Dave back out here toshow you the latest improvementsto Android that you'll get toexperience on Pixel Fold.
[Applause].

>>DAVE: Thanks, Rick.From new form factors andcustomizability to biometricsand computational photography,Android has always been at theforefront of mobile industrybreakthroughs.Recently, we've been working ona ton of features and improvements for largescreen devices like tablets and foldables.So who thinks we should try a bunch of livedemos on the new Pixel Fold?
[Cheers and Applause].
All right.It starts the second I unfoldthe device with this stunningwallpaper animation.The hinge sensor is actuallydriving the animation, and it'sa subtle thing, but it makes thedevice feel so dynamic andalive.Yeah, I just love that.All right.So let's go back to the folded state.And I'm looking through Googlephotos at a recent snowboardingtrip.Now, the scenery is really beautiful so Iwant to show you on the big screen.I just open my phone, and the video instantlyexpands into this gorgeous full screen view.
[Cheers and Applause].
We call this continuity, andwe've obsessed over everymillisecond it takes for apps toseamlessly adapt from thesmaller screen to the largerscreen.Now, all work and no play makesDavey a dull boy, so I'm goingto message my buddy aboutgetting back out on themountain.I can just swipe to bring up thenew Android taskbar, and then drag Googlemessages to the side to enter split screenmode like so.I'll send my buddy a photo totry to inspire him.I just drag and drop straightfrom Google Photos right into mymessage.Like so.And thanks to the new Jetpackdrag and drop library, this isnow supported in a wide varietyof apps from WorkSpace toWhatsApp.You'll notice we've made a bunchof improvements throughout theOS to take advantage of thelarger screen.So for example, here's the new split keyboardfor faster typing.And if I pull down from the top, you'll noticethe new two panel shade showing about my notificationsand my quick settings at the same time.Now, Pixel Fold is great for productivityon the go.And if I swipe up into Overview, you'll noticethat we now keep the multi tasking windowspaired.And for example, I was working on a GoogleDocs and Slides earlier to prep for this keynote,and I think I've I think I've followed mostof these tips so far, but I'm not quite doneyet.I can even adjust the split to suit the contentthat I'm viewing, and, you know, working thisway, it's like having a dual monitor set upin the palm of my hand, allowing me to dotwo things at once.Which reminds me, I should probably send Ricka quick note, so I'll open G mail and I don'thave a lot of time so I'm going to use thenew help me write feature, so let's try thisout.Don't cheer yet.Let's see if it works.Okay.Rick, congrats on what are we going to callthis, Pixel Fold's launch, amazing with Android.Okay.And then I probably should say, Dave not Andrew,Android.Dave.It's hard to type with all you people lookingat me.All right.Now, by the power of large language models,allow me to elaborate.Dear Rick, congratulations on the successfullaunch of Pixel Fold, I'm really impressedwith the device and how well it works withAndroid.The foldable screen is a game changer, andI can't wait to see what you do
[Cheers and Applause].
All right.That's productivity.But there's more.The Pixel Fold is also an awesome entertainmentdevice, and YouTube is just a really greatshowcase for this so let's start watchingthis video on the big screen.Now, look what happens when I fold the deviceat right angles.YouTube enters what we call tabletop modeso that the video plays on the top half andwe're working on adding playback controlson the bottom half for an awesome single handedlean back experience.And the video just keeps playing fluidly throughthese transitions without losing a beat.Okay.One last thing.We're adding support for switching displayswithin an app, and Pixel Fold's camera isa really great example of that.Now, by the way, say hi to Julie behind me.She's the real star of the show.
[Cheers and Applause].
So Pixel Fold has this new button on the bottomright so I'm going to tap this and it meansI can move the view finder to the outsidescreen.So let me turn the device around.Okay.So why is this interesting?Well, it means that the view finder is nowbeside the rear camera system and that meansI can get a high quality, ultra wide, amazingselfie with the best camera on the device.Speaking of which, and you knew where thiswas going!Smile, everybody!You look awesome!
[Cheers and Applause].
I always wanted to do that on Google I/O keynote.All right.So what you're seeing here is the culminationof several years of work, in fact, on largescreens, spanning the Android OS and the mostpopular apps on the play store.All this where it comes alive on the amazingnew Pixel Tablet and Pixel Fold, check outthis video.Thank you.They ain't never seen it like.This ain't never seen it likethis.This, this, this like this.Never seen it like this, this,this, this, this, like this.They ain't never seen it likethis.This.Like this.They ain't never seen it like this.
[Cheers and Applause].

>> That demo is awesome.Across Pixel and Android, we're making hugestrides with large screen devices, and wecan't wait to get Pixel Tablet and Pixel Foldinto your hands.And you're not going to have to wait too long.You can pre order Pixel Fold starting todayand it will ship next month.
[Cheers and Applause].
And you'll get the most out ofour first ultra premium foldable by pairingit with Pixel Watch.So when you pre order a Pixel Fold, you'llalso get a Pixel Watch on us.
[Cheers and Applause].
The Pixel family continues togrow into the most dynamicmobile hardware portfolio in themarket today.From a broad selection ofsmartphones to watches, earbuds,and now tablets and foldables,there are more ways than ever toexperience the helpfulness Pixelis known for whenever andwherever you need it.Now let me pass it back toSundar.Thanks, everyone!
[Cheers and Applause].

>>SUNDAR: Thanks, Rick.I'm really enjoying the newtablet and the first Pixelfoldable phone, and am proud ofthe progress Android is drivingacross the ecosystem.As we wrap up, I've beenreflecting on the big technologyshifts that we have all been apart of.The shift with AI is as big asthey come, and that's why it'sso important that we make AIhelpful for everyone.We are approaching it boldlywith a sense of excitement, andbecause as we look ahead, Google's deep understandingof information, combined with the capabilitiesof generative AI, can transform Search andall of our products yet again.And we are doing this responsibly in a waythat underscores the deep commitment we feelto get it right.No one company can do thisalone.Our developer community will bekey to unlocking the enormousopportunities ahead.We look forward to workingtogether and building together.So on behalf of all of us atGoogle, thank you, and enjoy therest of I/O.
